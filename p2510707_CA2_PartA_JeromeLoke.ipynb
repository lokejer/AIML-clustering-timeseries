{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab2f870",
   "metadata": {},
   "source": [
    "# **AIML CA2 Assignment - Part A (Clustering)**\n",
    "**Name**: JEROME LOKE  \n",
    "**Student ID**: P2510707  \n",
    "**Class**: DAAA/FT/1B/01  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca2b240",
   "metadata": {},
   "source": [
    "### **Tasks, and how I fulfilled them**\n",
    "##### → _\"Include some tests of your clustering with different possible values of k.\"_\n",
    "  - PCA (Principal Component Analysis) for a range of k-values\n",
    "  - t-SNE (T-distributed Stochastic Neighbour Embedding) for a range of perplexities and learning rates.\n",
    "  - Dendrogram\n",
    "  - 2D Scatter Plot\n",
    "\n",
    "##### → _\"Determine the best possible value of k. And show how you can determine that this is the best value for k.\"_  \n",
    "  - Elbow Method\n",
    "  - Silhouette Score\n",
    "  - Silhouette Plot\n",
    "  - Davies Bouldin Index\n",
    "  - Calinski-Harabasz Score\n",
    "\n",
    "##### → _\"Use more than just one clustering algorithm (so, not just k-means).\"_\n",
    "  - Agglomerative Clustering\n",
    "  - KMeans\n",
    "\n",
    "### **Machine Learning Workflow**\n",
    "1. EDA\n",
    "2. Data Preprocessing \n",
    "3. Feature Engineering \n",
    "4. Employing Clustering Algorithms\n",
    "5. Model Evaluation\n",
    "6. Interpretation / Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11627cdc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Model training\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9aae35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STAGE 1: EDA (Exploratory Data Analysis)**\n",
    "* **Preview Dataset**: Display first 5 rows to understand its structure.\n",
    "* **Shape**: Dataset has X rows and Y columns.\n",
    "* **Info & Summary Statistics**: Analyse data types, non-missing counts, and key statistics (mean, standard deviation, etc.) for numerical columns.\n",
    "* **Investigate Irregular Data**: Use intuition to identify and resolve irregular data like negative prices or abnormally large Age values.\n",
    "* **Visualise Distributions**: Perform univariate and bivariate analysis using matplotlib and seaborn to identify patterns.\n",
    "* **Missing Values**: Identify missing values per column / overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063d9c7",
   "metadata": {},
   "source": [
    "### Load & Preview Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./CA2-datasets/CA2-Customer-Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b53437",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"rows: {df.shape[0]}, cols: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce0fe2",
   "metadata": {},
   "source": [
    "### Investigate Irregularities in Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ac41e",
   "metadata": {},
   "source": [
    "#### dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3596da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cfdd43",
   "metadata": {},
   "source": [
    "* No necessary edits needed for column dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd498c3",
   "metadata": {},
   "source": [
    "#### Features (numerical then categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05082011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d0b50",
   "metadata": {},
   "source": [
    "* Mean `Age` is ~39  \n",
    "\n",
    "* Mean `Income (k$)` is ~60.6k$  \n",
    "\n",
    "* #### **Key Observation:** `How Much They Spend` has no labelled unit, and interestingly ranges from 1.0 to 99.0. This suggests that this feature could represent a \"spending score\" of 1-99 instead of raw \"money spent\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09efc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90b36c",
   "metadata": {},
   "source": [
    "* `Gender` shows an imbalance (112 Females : 88 Males), might influence our clusters later on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daecc331",
   "metadata": {},
   "source": [
    "#### Investigate `How Much They Spend`\n",
    "Intuitively, this feature would represent the amount of money spent by each customer. However, the range of this feature is only between 1 - 99, which is strange as real-world data rarely caps at 99 so cleanly.  \n",
    "We will investigate the feature's distributions to see whether it represents an engineered score between 1-99 or not.  \n",
    "\n",
    "Key Assumptions:\n",
    "* Real-world money data should be right-skewed\n",
    "* Richer customers should have higher input values for this feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f72461",
   "metadata": {},
   "source": [
    "##### 1. Distributions of `How Much They Spend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# histogram\n",
    "sns.histplot(df[\"How Much They Spend\"], bins=20, kde=True, ax=axes[0])\n",
    "axes[0].set_title(\"Distribution of Spending\")\n",
    "axes[0].set_xlabel(\"How Much They Spend\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "# boxplot\n",
    "sns.boxplot(x=df[\"How Much They Spend\"], ax=axes[1])\n",
    "axes[1].set_title(\"Spending Boxplot\")\n",
    "axes[1].set_xlabel(\"How Much They Spend\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Median:\", df[\"How Much They Spend\"].median())\n",
    "print(\"Q1:\", df[\"How Much They Spend\"].quantile(0.25))\n",
    "print(\"Q3:\", df[\"How Much They Spend\"].quantile(0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9ad15",
   "metadata": {},
   "source": [
    "* How Much They Spend displays a trimodal distribution instead of a right-skew, which supports the hypothesis that it the feature represents an engineered Spending Score of 1-99 instead of a raw spending amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786260e",
   "metadata": {},
   "source": [
    "##### 2. `Income (k$)` VS `How Much They Spend`\n",
    "\"Do richer people tend to spend more?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation coefficient\n",
    "corr = df[\"Income (k$)\"].corr(df[\"How Much They Spend\"])\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df, x=\"Income (k$)\", y=\"How Much They Spend\")\n",
    "plt.title(f\"Income (k$) vs Spending (r = {corr:.2f})\")\n",
    "plt.xlabel(\"Income (k$)\")\n",
    "plt.ylabel(\"How Much They Spend\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24518be",
   "metadata": {},
   "source": [
    "* There is a ***weak*** positive relationship between `Income (k$)` and `How Much They Spend`, suggesting that richer people do not tend to spend more.  \n",
    "\n",
    "* The low Pearson correlation points to the fact that these features are more suitable for customer segmentation than linear prediction. Customers were naturally separated into clusters as shown from the scatter plot. For instance, all high-earning customers (Income (k$) > 70) are separated into two groups: High spending and Low spending.\n",
    "\n",
    "* Shows that Income (k$) and How Much They Spend separates customers meaningfully (helps distinguish customer types). The clear 'X' structure formed suggests they are strong features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84d4a9",
   "metadata": {},
   "source": [
    "##### 3. Spending by Age Group\n",
    "Split customers into five specific age ranges and compare their respective spending.  \n",
    "\n",
    "\"Do older customers tend to spend less?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c78fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age Group\"] = pd.cut(\n",
    "  df[\"Age\"],\n",
    "  bins=[17, 25, 35, 45, 55, 70]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.boxplot(data=df, x=\"Age Group\", y=\"How Much They Spend\")\n",
    "plt.title(\"Spending by Age Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771ecce",
   "metadata": {},
   "source": [
    "* Highest spending at the 26-35years age group, indicating young working adults show the highest spending potential.\n",
    "\n",
    "* Widest variety of spending at the 36-45years age group, suggesting strong potential for growth via targeted campaigns.\n",
    "\n",
    "* Older folks have a wider variety of spenders, with some spending way below the average (see the minimum). However, the median (Q2) spending of the 56-70years age group is actually higher than the 36-45 and 46-55 age groups, suggesting that older folks do not spend the least."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c38058",
   "metadata": {},
   "source": [
    "##### Conclusion: `How Much They Spend` = `Spending Score (1-99)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa2ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(\n",
    "  columns={'How Much They Spend': 'Spending Score (1-99)'},\n",
    "  inplace=True\n",
    ")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d0dfdc",
   "metadata": {},
   "source": [
    "#### Visualise `Age` Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d79a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "sns.histplot(df[\"Age\"], bins=20, kde=True)\n",
    "plt.title(\"Distribution of Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Median:\", df[\"Age\"].median())\n",
    "print(\"Q1:\", df[\"Age\"].quantile(0.25))\n",
    "print(\"Q3:\", df[\"Age\"].quantile(0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a36092",
   "metadata": {},
   "source": [
    "#### Visualise `Gender` Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95944b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the values in 'Gender'\n",
    "gender_counts = df['Gender'].value_counts()\n",
    "\n",
    "# bar chart\n",
    "plt.figure(figsize=(6, 4))\n",
    "barplot = sns.barplot(\n",
    "  x=gender_counts.index, \n",
    "  y=gender_counts.values, \n",
    "  palette=['pink', 'darkblue']\n",
    ")\n",
    "\n",
    "# data labels\n",
    "for i, count in enumerate(gender_counts.values):\n",
    "  plt.text(i, count + 1, str(count), ha='center', fontsize=8)\n",
    "\n",
    "plt.title('Gender Distribution', fontsize=16)\n",
    "plt.xlabel('Gender', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4f800",
   "metadata": {},
   "source": [
    "### Bivariate Analysis: Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily encode categorical variable Gender\n",
    "temp_df = df.copy()\n",
    "temp_df['Gender'] = temp_df['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# get the correlation matrix for numerical columns only\n",
    "correlation_matrix = temp_df.drop(columns=['CustomerID', 'Age Group']).corr()\n",
    "\n",
    "# heatmap\n",
    "plt.figure(figsize=(10, 8))                     \n",
    "sns.heatmap(\n",
    "  correlation_matrix, annot=True,      \n",
    "  cmap='Spectral',                     \n",
    "  fmt=\".2f\",                          \n",
    "  linewidths=0.5, linecolor='gray')   \n",
    "plt.title('Correlation between variables')         \n",
    "plt.xticks(rotation=45)                          \n",
    "plt.yticks(rotation=0)                           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f6b00",
   "metadata": {},
   "source": [
    "* Age and Spending Score (1-99):\n",
    "  * Negative correlation (-0.33), highlighted in red, suggests that older customers tend to spend less.\n",
    "\n",
    "* Income and Spending Score (1-99):\n",
    "  * Displays negligible correlation (0.01), represented in orange/yellow, indicating that income does not significantly influence spending patterns.\n",
    "\n",
    "* Age and Income:\n",
    "  * A weak negative correlation (-0.01) suggests no meaningful relationship between a customer's age and income level.\n",
    "\n",
    "**Key Insights**\n",
    "1. Age shows the strongest relationship with spending among the features, making it a valuable variable for customer segmentation.\n",
    "2. Income and Spending Score (1-99) lack a meaningful correlation, implying income alone may not drive customer spending behaviour.\n",
    "3. This analysis helps us identify which variables may be more significant when forming clusters, ensuring a focused and effective clustering approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13171e9a",
   "metadata": {},
   "source": [
    "### Bivariate Analysis: Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88307c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot = sns.pairplot(\n",
    "  df,\n",
    "  vars=[\"Age\", \"Income (k$)\", \"Spending Score (1-99)\"],\n",
    "  hue=\"Gender\", # hue to highlight gender differences\n",
    "  diag_kind=\"kde\",\n",
    "  palette=['blue','pink'],\n",
    "  height=2.5,\n",
    ")\n",
    "\n",
    "pairplot.fig.suptitle(\"Pairplot of Numerical Features with Gender Hue\", y=1.02, fontsize=14, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06faa9ac",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "* Age Distribution (Top Left)\n",
    "  * Both genders show similar age distributions, with most customers falling between 20-40 years old.\n",
    "  * The distributions overlap substantially, indicating the store attracts similar age groups regardless of gender. The only noteworthy difference is the maximum age for females is much higher than that of males.\n",
    "\n",
    "* Annual Income Distribution (Center)\n",
    "  * Income distributions are similar for both genders, ranging from about $15k to $140k, with most customers earning between $50k-100k. This suggests income is independent of gender in this customer base.\n",
    "\n",
    "* Spending Score Distribution (Bottom Right)\n",
    "  * Spending scores range from 1-100. Females have higher spending scores than males on average, suggesting that females spend more than males.\n",
    "\n",
    "* Age vs Annual Income (Row 2, Column 1)\n",
    "  * The scatter plot shows no clear relationship between age and income. Customers across all age groups have varied income levels, distributed fairly randomly. Gender does not appear to influence this relationship.\n",
    "\n",
    "* Age vs Spending Score (Row 3, Column 1)\n",
    "  * There is no strong correlation between age and spending behavior. However, younger customers (under 40) show the full range of spending scores, while older customers (over 50) tend to cluster in the middle spending ranges.\n",
    "\n",
    "* Annual Income vs Spending Score (Row 3, Column 2)\n",
    "  * This is the most interesting relationship. The data suggests potential customer segments: high income with high spending, high income with low spending, low income with high spending, and low income with low spending. These visible clusters could be useful for targeted marketing strategies and shows that our data already contains natural clusters. KMeans is a potential algorithm.\n",
    "\n",
    "**Business Implications:**\n",
    "* For retail startups, this data suggests that **gender-based strategies may not be necessary** since spending patterns are similar across genders. Instead, **customer segments can be identified based on their income-spending relationship**.  \n",
    "* The clusters visible in the income vs spending plot indicate distinct customer groups that likely require different marketing approaches and product offerings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efda97f",
   "metadata": {},
   "source": [
    "### Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98993590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4516f57",
   "metadata": {},
   "source": [
    "* Dataset contains no missing data.  \n",
    "\n",
    "* Investigated and resolved column `How Much They Spend` by renaming it to `Spending Score (1-99)`.  \n",
    "\n",
    "* No irregularities found in remaining column data (e.g. entries containing negative `Income (k$)` or huge `Age` values).  \n",
    "\n",
    "* Dataset is ready to be preprocessed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf69f9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STAGE 2: Data Preprocessing**\n",
    "* **Remove ID Features**: Drop `CustomerID`\n",
    "* **Remove Duplicates**: Drop duplicate rows\n",
    "* **StandardScaler**: Scale features to prevent them from dominating euclidean distance-based algorithms like KMeans\n",
    "* **One-Hot Encoding**: Encode categorical features  \n",
    "* **Outlier Detection with IsolationForest**: Detect extreme outliers to evaluate whether StandardScaler is suitable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c0573",
   "metadata": {},
   "source": [
    "### Remove ID & Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b1a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.drop(columns=['CustomerID'])\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Dropped CustomerID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc9359",
   "metadata": {},
   "source": [
    "### One-Hot Encoding `Gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bf293",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "one_hot_gender = encoder.fit_transform(df[[\"Gender\"]])\n",
    "\n",
    "df = df.join(\n",
    "  pd.DataFrame(one_hot_gender, columns=encoder.get_feature_names_out([\"Gender\"]))\n",
    ").drop(columns=\"Gender\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d766a",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe225a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_features = [\"Age\", \"Income (k$)\", \"Spending Score (1-99)\"]\n",
    "\n",
    "# scale features and apply PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[outlier_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa5261",
   "metadata": {},
   "source": [
    "### Investigating Outliers with IsolationForest\n",
    "\"How extreme are this dataset's outliers?\"  \n",
    "\"How might the outliers affect my preprocessing steps like StandardScaler?\"  \n",
    "\"After visualising the dataset with outliers flagged, which algorithms might struggle on this dataset?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdcaff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Isolation Forest\n",
    "iso = IsolationForest(\n",
    "  n_estimators=100,\n",
    "  contamination=0.05,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "df['Outlier'] = iso.fit_predict(df[outlier_features])\n",
    "\n",
    "# count outliers\n",
    "n_outliers = (df['Outlier'] == -1).sum()\n",
    "n_normal = (df['Outlier'] == 1).sum()\n",
    "\n",
    "# prepare data splits\n",
    "normal = df[df['Outlier'] == 1]\n",
    "outliers = df[df['Outlier'] == -1] if n_outliers > 0 else None\n",
    "\n",
    "# instantiate PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df['PCA1'] = X_pca[:, 0]\n",
    "df['PCA2'] = X_pca[:, 1]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outliers in both feature space and PCA space\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# feature Space: Income vs Spending\n",
    "axes[0].scatter(\n",
    "  normal[\"Income (k$)\"], \n",
    "  normal[\"Spending Score (1-99)\"], \n",
    "  alpha=0.6, s=40, color='steelblue', \n",
    "  label=f'Normal (n={n_normal})', \n",
    "  edgecolors='black', linewidth=0.3\n",
    ")\n",
    "\n",
    "if n_outliers > 0:\n",
    "  axes[0].scatter(\n",
    "    outliers[\"Income (k$)\"], \n",
    "    outliers[\"Spending Score (1-99)\"], \n",
    "    alpha=0.9, s=40, color='red', marker='o',\n",
    "    label=f'Outliers (n={n_outliers})', \n",
    "    edgecolors='darkred', linewidth=1.5\n",
    "  )\n",
    "\n",
    "axes[0].set_xlabel(\"Income (k$)\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Spending Score (1-99)\", fontsize=12)\n",
    "axes[0].set_title(\"Outlier Detection: Feature Space\\n(Income vs Spending)\", fontsize=13, fontweight='bold')\n",
    "axes[0].legend(loc='best')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PCA Space: compressed features\n",
    "normal_pca = df[df['Outlier'] == 1]\n",
    "axes[1].scatter(\n",
    "  normal_pca['PCA1'], \n",
    "  normal_pca['PCA2'], \n",
    "  alpha=0.6, s=40, color='steelblue', \n",
    "  label=f'Normal (n={n_normal})', \n",
    "  edgecolors='black', linewidth=0.3\n",
    ")\n",
    "\n",
    "if n_outliers > 0:\n",
    "  outliers_pca = df[df['Outlier'] == -1]\n",
    "  axes[1].scatter(\n",
    "    outliers_pca['PCA1'], \n",
    "    outliers_pca['PCA2'], \n",
    "    alpha=0.9, s=40, color='red', marker='o',\n",
    "    label=f'Outliers (n={n_outliers})', \n",
    "    edgecolors='darkred',\n",
    "  )\n",
    "\n",
    "var_explained = pca.explained_variance_ratio_\n",
    "axes[1].set_xlabel(f\"PC1 ({var_explained[0]*100:.1f}% variance)\", fontsize=12)\n",
    "axes[1].set_ylabel(f\"PC2 ({var_explained[1]*100:.1f}% variance)\", fontsize=12)\n",
    "axes[1].set_title(\"Outlier Detection: PCA Space\\n(Age + Income + Spending)\", fontsize=13, fontweight='bold')\n",
    "axes[1].legend(loc='best')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba662d",
   "metadata": {},
   "source": [
    "#### Conclude Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e944671",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_outliers > 0:\n",
    "  comparison_df = pd.DataFrame({\n",
    "    'Normal (Mean)': round(normal[outlier_features].mean(), 3),\n",
    "    'Outliers (Mean)': round(outliers[outlier_features].mean(), 3),\n",
    "    'Difference': round(outliers[outlier_features].mean() - normal[outlier_features].mean(), 3)\n",
    "  })\n",
    "\n",
    "df = df.drop(columns=['PCA1', 'PCA2', 'Outlier']) # clean up temporary columns\n",
    "\n",
    "print(\"Outlier vs Normal Comparison:\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2421bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers[outlier_features].describe().loc[[\"min\", \"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa138b",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "\"How extreme are this dataset's outliers?\"  \n",
    "* Not extreme, Age has a miniscule difference of -0.158 while Income and Spending Score differ by $5,516 and -15 respectively.\n",
    "* I will keep outliers as they represent high-income, low-spending customers, which form a meaningful customer segment rather than data errors. Removing them would reduce the interpretability of the clustering results.\n",
    "\n",
    "\"How might the outliers affect my preprocessing steps like StandardScaler?\"  \n",
    "* Lack of extreme outliers suggest that StandardScaler is appropiate.\n",
    "\n",
    "* Proves that StandardScaler is more appropiate than MinMaxScaler:\n",
    "  * Outliers are behaviourally meaningful, not errors → MinMax would stretch the scale around them\n",
    "  * Relative differences between customers matter\n",
    "  * StandardScaler maintains cluster structure better under K-Means\n",
    "\n",
    "\"After visualising the dataset with outliers flagged, which algorithms might struggle on this dataset?\"\n",
    "* Algorithms like KMeans should perform well as the data showed natural clusters (see Feature Space of Income VS Spending Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a353d5c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STAGE 3: Feature Engineering**\n",
    "* **Create Relationship Features**: Create features that reflect behaviours or patterns, not raw values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e39669",
   "metadata": {},
   "source": [
    "### `Spending_Income_Ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b75e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Spend_Income_Ratio\"] = df[\"Spending Score (1-99)\"] / df[\"Income (k$)\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6129eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Spend_Income_Ratio'], bins=10, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681ce1c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Finalise Input Features**\n",
    "KMeans clustering works best when a small number of **meaningful** features are used.  \n",
    "Including too many features can increase complexity and reduce the quality of the clusters formed. Therefore, features that do not contribute to clearer or more distinct clusters should be excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b17691",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Experiment: Include `Gender` or not?\n",
    "* Use sklearn's Pipeline to streamline the model training process\n",
    "* Exclude engineered features first, only include them later to ensure the clustering is actually due to Gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_gender = [\n",
    "  \"Age\",\n",
    "  \"Income (k$)\",\n",
    "  \"Spending Score (1-99)\",\n",
    "  \"Gender_Male\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ce62d",
   "metadata": {},
   "source": [
    "##### KMeans without `Gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32fb2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_no_gender = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"num\", StandardScaler(), features_with_gender[:-1]) # exclude the last element in the features list: Gender)\n",
    "  ]\n",
    ")\n",
    "\n",
    "pipeline_no_gender = Pipeline(\n",
    "  steps=[\n",
    "    (\"preprocess\", preprocess_no_gender),\n",
    "    (\"kmeans\", KMeans(n_clusters=5, random_state=42))\n",
    "  ]\n",
    ")\n",
    "\n",
    "df[\"Cluster_No_Gender\"] = pipeline_no_gender.fit_predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cf3be",
   "metadata": {},
   "source": [
    "##### KMeans with `Gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_with_gender = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"num\", StandardScaler(), features_with_gender) # includes Gender\n",
    "  ]\n",
    ")\n",
    "\n",
    "pipeline_with_gender = Pipeline(\n",
    "  steps=[\n",
    "    (\"preprocess\", preprocess_with_gender),\n",
    "    (\"kmeans\", KMeans(n_clusters=5, random_state=42))\n",
    "  ]\n",
    ")\n",
    "\n",
    "df[\"Cluster_With_Gender\"] = pipeline_with_gender.fit_predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d40449",
   "metadata": {},
   "source": [
    "##### Compare Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc295c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharex=True, sharey=True)\n",
    "\n",
    "# WITH Gender\n",
    "sns.scatterplot(\n",
    "  data=df,\n",
    "  x=\"Income (k$)\",\n",
    "  y=\"Spending Score (1-99)\",\n",
    "  hue=\"Cluster_With_Gender\",\n",
    "  palette=\"tab10\",\n",
    "  ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Clusters WITH Gender\")\n",
    "axes[0].legend(title=\"Cluster\", fontsize=8)\n",
    "\n",
    "# WITHOUT Gender\n",
    "sns.scatterplot(\n",
    "  data=df,\n",
    "  x=\"Income (k$)\",\n",
    "  y=\"Spending Score (1-99)\",\n",
    "  hue=\"Cluster_No_Gender\",\n",
    "  palette=\"tab10\",\n",
    "  ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Clusters WITHOUT Gender\")\n",
    "axes[1].legend(title=\"Cluster\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# clean up df\n",
    "df = df.drop(columns=[\"Cluster_No_Gender\", \"Cluster_With_Gender\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ae5c3",
   "metadata": {},
   "source": [
    "Conclusion: Exclude `Gender` as it does not help create more meaningful clusters and only adds noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec19d5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Experiment: `Spend_Income_Ratio`\n",
    "Is the engineered feature useful? Does it help clusters form more distinctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0387126",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_ratio = [\n",
    "  \"Age\",\n",
    "  \"Income (k$)\",\n",
    "  \"Spending Score (1-99)\",\n",
    "  \"Spend_Income_Ratio\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88229213",
   "metadata": {},
   "source": [
    "##### KMeans without `Spend_Income_Ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_no_ratio = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"num\", StandardScaler(), features_with_ratio[:-1])\n",
    "  ]\n",
    ")\n",
    "\n",
    "pipeline_no_ratio = Pipeline(\n",
    "  steps=[\n",
    "    (\"preprocess\", preprocess_no_ratio),\n",
    "    (\"kmeans\", KMeans(n_clusters=5, random_state=42))\n",
    "  ]\n",
    ")\n",
    "\n",
    "df[\"Cluster_No_Ratio\"] = pipeline_no_ratio.fit_predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c688e",
   "metadata": {},
   "source": [
    "##### KMeans with `Spend_Income_Ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_with_ratio = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"num\", StandardScaler(), features_with_ratio)\n",
    "  ]\n",
    ")\n",
    "\n",
    "pipeline_with_ratio = Pipeline(\n",
    "  steps=[\n",
    "    (\"preprocess\", preprocess_with_ratio),\n",
    "    (\"kmeans\", KMeans(n_clusters=5, random_state=42))\n",
    "  ]\n",
    ")\n",
    "\n",
    "df[\"Cluster_With_Ratio\"] = pipeline_with_ratio.fit_predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80da0f8",
   "metadata": {},
   "source": [
    "#### Compare Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharex=True, sharey=True)\n",
    "\n",
    "# WITH ratio \n",
    "sns.scatterplot(\n",
    "  data=df,\n",
    "  x=\"Income (k$)\",\n",
    "  y=\"Spending Score (1-99)\",\n",
    "  hue=\"Cluster_With_Ratio\",\n",
    "  palette=\"tab10\",\n",
    "  ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Clusters WITH Ratio\")\n",
    "axes[0].legend(title=\"Cluster\", fontsize=8)\n",
    "\n",
    "# WITHOUT Ratio\n",
    "sns.scatterplot(\n",
    "  data=df,\n",
    "  x=\"Income (k$)\",\n",
    "  y=\"Spending Score (1-99)\",\n",
    "  hue=\"Cluster_No_Ratio\",\n",
    "  palette=\"tab10\",\n",
    "  ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Clusters WITHOUT Ratio\")\n",
    "axes[1].legend(title=\"Cluster\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# clean up df\n",
    "df = df.drop(columns=[\"Cluster_No_Ratio\", \"Cluster_With_Ratio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa8e30",
   "metadata": {},
   "source": [
    "Conclusion: Although `Spending_Income_Ratio` helped to resolve a small amount of mess/overlap in our clusters, its impact on the clustering was not substantial. Thus, I will not keep this feature as keeping it would likely just increase our model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db99e82",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Compare Scaled VS Unscaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "  \"Age\",\n",
    "  \"Income (k$)\",\n",
    "  \"Spending Score (1-99)\",\n",
    "  # concluded to exclude gender and spend_income_ratio\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b9f27",
   "metadata": {},
   "source": [
    "#### Raw/Unscaled Features\n",
    "The preprocessing step in the previous pipelines on Gender and Ratio filtered out non-numeric features, preventing interval-type data from being passed into the KMeans algorithm.  \n",
    "This pipeline has no preprocessor, so I have to manually pass in the features when fitting KMeans in pipeline.fit_predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909dd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_no_scale = Pipeline(\n",
    "  steps=[\n",
    "    (\"kmeans\", KMeans(n_clusters=5, random_state=42))\n",
    "  ]\n",
    ")\n",
    "\n",
    "df[\"Cluster_Unscaled\"] = pipeline_no_scale.fit_predict(df[features])\n",
    "\n",
    "# calculate silhouette score\n",
    "X_unscaled = df[features].values\n",
    "labels_unscaled = df[\"Cluster_Unscaled\"]\n",
    "silhouette_unscaled = silhouette_score(X_unscaled, labels_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cf60f",
   "metadata": {},
   "source": [
    "#### Scaled Features\n",
    "The preprocessor drops all the columns not specified in the list features. Thus, I do not have to manually pass in the features when fitting KMeans in pipeline.fit_predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4195d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_with_scale = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"num\", StandardScaler(), features)\n",
    "  ]\n",
    ")\n",
    "\n",
    "pipeline_with_scale = Pipeline(\n",
    "  steps=[\n",
    "    (\"preprocess\", preprocess_with_scale),\n",
    "    (\"kmeans\", KMeans(n_clusters=5, random_state=42))\n",
    "  ]\n",
    ")\n",
    "\n",
    "df[\"Cluster_Scaled\"] = pipeline_with_scale.fit_predict(df)\n",
    "\n",
    "# calculate silhouette score\n",
    "X_scaled = pipeline_with_scale.named_steps[\"preprocess\"].transform(df)\n",
    "labels_scaled = df[\"Cluster_Scaled\"]\n",
    "silhouette_scaled = silhouette_score(X_scaled, labels_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed75b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharex=True, sharey=True)\n",
    "\n",
    "# WITH scaling\n",
    "sns.scatterplot(\n",
    "  data=df,\n",
    "  x=\"Income (k$)\",\n",
    "  y=\"Spending Score (1-99)\",\n",
    "  hue=\"Cluster_Scaled\",\n",
    "  palette=\"tab10\",\n",
    "  ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(f\"Clusters WITH Scaled Features\\nSilhouette Score:{silhouette_scaled:.2f}\")\n",
    "axes[0].legend(title=\"Cluster\", fontsize=8)\n",
    "\n",
    "# WITHOUT scaling\n",
    "sns.scatterplot(\n",
    "  data=df,\n",
    "  x=\"Income (k$)\",\n",
    "  y=\"Spending Score (1-99)\",\n",
    "  hue=\"Cluster_Unscaled\",\n",
    "  palette=\"tab10\",\n",
    "  ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(f\"Clusters WITHOUT Scaled Features\\nSilhouette Score: {silhouette_unscaled:.2f}\")\n",
    "axes[1].legend(title=\"Cluster\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f56a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Cluster_Scaled\", \"Cluster_Unscaled\"], inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edc2a6",
   "metadata": {},
   "source": [
    "### Extract & Visualise Scaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08980dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pipeline_with_scale.named_steps[\"preprocess\"].transform(df[features])\n",
    "feature_names = pipeline_with_scale.named_steps[\n",
    "  \"preprocess\"\n",
    "].get_feature_names_out()\n",
    "\n",
    "clean_names = [name.replace(\"num__\", \"\") for name in feature_names]\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=clean_names)\n",
    "X_scaled_df = X_scaled_df.add_suffix(\"_scaled\")\n",
    "df = pd.concat([df, X_scaled_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21f704",
   "metadata": {},
   "source": [
    "#### Normalised Distribution: mean 0, std 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_cols = [\n",
    "  \"Age_scaled\",\n",
    "  \"Income (k$)_scaled\",\n",
    "  \"Spending Score (1-99)_scaled\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for col in scaled_cols:\n",
    "  sns.histplot(df[col], kde=True, label=col, bins=30)\n",
    "\n",
    "plt.title(\"Distribution of Scaled Features\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[scaled_cols].describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7471fda4",
   "metadata": {},
   "source": [
    "### Analyze Finalised Features\n",
    "* `Age_scaled`\n",
    "\n",
    "* `Income (k$)_scaled`\n",
    "\n",
    "* `Spending Score (1-99)_scaled`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa8be0",
   "metadata": {},
   "source": [
    "#### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ca524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# calculate importance as weighted sum of absolute loadings\n",
    "weights = pca.explained_variance_ratio_\n",
    "feature_importance = (\n",
    "  np.abs(pca.components_[0]) * weights[0] + \n",
    "  np.abs(pca.components_[1]) * weights[1]\n",
    ")\n",
    "importance_df = pd.DataFrame({\n",
    "  'Feature': features,\n",
    "  'Importance Score': feature_importance,\n",
    "  'Importance (%)': (feature_importance / feature_importance.sum()) * 100\n",
    "}).sort_values('Importance Score', ascending=True)\n",
    "\n",
    "# plot bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "colors = ['lightblue', 'lightgreen', 'indianred']\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance (%)'], color=colors, edgecolor='black')\n",
    "plt.xlabel('Importance (%)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Overall Feature Importance for Clustering\\n(Based on PC1 + PC2)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6249a029",
   "metadata": {},
   "source": [
    "I would say all features are equally important for our clustering, income is only slightly more important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b071eff",
   "metadata": {},
   "source": [
    "#### Scree Plot for Variance Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90debcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate PCA with 3 components to capture all variance\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "variance_df = pd.DataFrame({\n",
    "  'Component': [f'PC{i+1}' for i in range(len(pca.explained_variance_ratio_))],\n",
    "  'Variance Explained (%)': pca.explained_variance_ratio_ * 100,\n",
    "  'Cumulative Variance (%)': np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "})\n",
    "\n",
    "# scree plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.bar(\n",
    "  range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "  pca.explained_variance_ratio_ * 100, \n",
    "  color='skyblue', edgecolor='black'\n",
    ")\n",
    "plt.plot(\n",
    "  range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "  np.cumsum(pca.explained_variance_ratio_) * 100, \n",
    "  color='red', marker='o', linewidth=2, label='Cumulative'\n",
    ")\n",
    "plt.xlabel('Principal Component', fontsize=12)\n",
    "plt.ylabel('Variance Explained (%)', fontsize=12)\n",
    "plt.title('Scree Plot: Variance Explained by Each PC', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1, len(pca.explained_variance_ratio_) + 1))\n",
    "\n",
    "print(f\"\\nPC1 + PC2 capture {variance_df.iloc[1]['Cumulative Variance (%)']:.1f}% of total variance\")\n",
    "variance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61226e",
   "metadata": {},
   "source": [
    "PC1 and PC2 already capture nearly 80% variance in data. PC3 is unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f160f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STAGE 4: Employing Clustering Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb3fcd",
   "metadata": {},
   "source": [
    "### Find Optimal k-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c146c80",
   "metadata": {},
   "source": [
    "#### Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f23cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "\n",
    "for k in range(2, 11):\n",
    "  km = KMeans(n_clusters=k, random_state=42)\n",
    "  km.fit(X_scaled)\n",
    "  inertia.append(km.inertia_)\n",
    "\n",
    "plt.plot(range(2, 11), inertia, marker=\"o\")\n",
    "plt.xlabel(\"Number of clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Elbow Method for K-Means\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2804d8b",
   "metadata": {},
   "source": [
    "#### Silhouette Score\n",
    "\n",
    "![Silhouette Score Formula](\"silhouette_score_formula.png\")\n",
    "\n",
    "a(i) = average distance to points in the same cluster  \n",
    "b(i) = average distance to points in the nearest other cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792319b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2, 10)\n",
    "\n",
    "evaluation_metrics = {\n",
    "  'silhouette': {},\n",
    "  'davies_bouldin': {},\n",
    "  'calinski_harabasz': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_range: # check sil scores for k=2 to k=9 \n",
    "  km = KMeans(n_clusters=k, random_state=42)\n",
    "  labels = km.fit_predict(X_scaled)\n",
    "  score = silhouette_score(X_scaled, labels)\n",
    "  evaluation_metrics[\"silhouette\"][k] = round(score, 3)\n",
    "  print(f\"k={k}, silhouette={evaluation_metrics[\"silhouette\"][k]}\")\n",
    "\n",
    "# plot silhouette scores vs k\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, evaluation_metrics[\"silhouette\"].values(), marker='o', linestyle='-', color='purple')\n",
    "plt.xticks(k_range)\n",
    "plt.xlabel(\"Number of clusters k\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Score vs Number of Clusters\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b211cc06",
   "metadata": {},
   "source": [
    "#### Davies-Bouldin Index, Calinski-Harabasz Score\n",
    "\n",
    "##### **DBI**\n",
    "![DBI formula](attachment:image-2.png)\n",
    "- Measures the average similarity ratio of each cluster with its most similar cluster\n",
    "- Lower is better (0 is perfect, but unrealistic)\n",
    "- Good values typically < 1.0\n",
    "- Considers both cluster compactness (tight clusters) and separation (distance between clusters)\n",
    "- Formula: Ratio of within-cluster distances to between-cluster distances\n",
    "\n",
    "##### **Calinski-Harabasz**\n",
    "![CBS formula](attachment:image.png)\n",
    "- Ratio of between-cluster variance to within-cluster variance\n",
    "- Higher is better (more separated clusters)\n",
    "- No fixed \"good\" threshold, compare relative values\n",
    "- Fast to compute, works well with convex clusters\n",
    "- Tends to favor more clusters than silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26576b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "  km = KMeans(n_clusters=k, random_state=42)\n",
    "  labels = km.fit_predict(X_scaled)\n",
    "  \n",
    "  # Calculate all three metrics\n",
    "  db_score = davies_bouldin_score(X_scaled, labels)\n",
    "  ch_score = calinski_harabasz_score(X_scaled, labels)\n",
    "  \n",
    "  # Store results\n",
    "  evaluation_metrics['davies_bouldin'][k] = round(db_score, 3)\n",
    "  evaluation_metrics['calinski_harabasz'][k] = round(ch_score, 2)\n",
    "\n",
    "# Determine optimal k based on each metric\n",
    "optimal_k_db = min(evaluation_metrics['davies_bouldin'], \n",
    "                   key=evaluation_metrics['davies_bouldin'].get)\n",
    "optimal_k_ch = max(evaluation_metrics['calinski_harabasz'], \n",
    "                   key=evaluation_metrics['calinski_harabasz'].get)\n",
    "\n",
    "print(\"OPTIMAL k VALUES:\")\n",
    "print(f\"  Davies-Bouldin Index (lower is better): k = {optimal_k_db}\")\n",
    "print(f\"  Calinski-Harabasz Score (higher is better): k = {optimal_k_ch}\")\n",
    "\n",
    "# plot metric visualisations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Davies-Bouldin Index\n",
    "axes[0].plot(k_range, evaluation_metrics['davies_bouldin'].values(), \n",
    "             marker='s', linestyle='-', color='orange', linewidth=2)\n",
    "axes[0].axvline(optimal_k_db, color='red', linestyle='--', \n",
    "                label=f'Optimal k={optimal_k_db}')\n",
    "axes[0].set_xlabel(\"Number of Clusters (k)\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Davies-Bouldin Index\", fontsize=12)\n",
    "axes[0].set_title(\"Davies-Bouldin Index\\n(Lower is Better)\", fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "axes[0].set_xticks(k_range)\n",
    "\n",
    "# Calinski-Harabasz Score\n",
    "axes[1].plot(k_range, evaluation_metrics['calinski_harabasz'].values(), \n",
    "             marker='^', linestyle='-', color='green', linewidth=2)\n",
    "axes[1].axvline(optimal_k_ch, color='red', linestyle='--', \n",
    "                label=f'Optimal k={optimal_k_ch}')\n",
    "axes[1].set_xlabel(\"Number of Clusters (k)\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Calinski-Harabasz Score\", fontsize=12)\n",
    "axes[1].set_title(\"Calinski-Harabasz Score\\n(Higher is Better)\", fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "axes[1].set_xticks(k_range)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# create summary DataFrame of metric data\n",
    "metrics_df = pd.DataFrame(evaluation_metrics)\n",
    "metrics_df.index.name = 'k'\n",
    "print(\"\\nMetrics Summary Table:\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a341429",
   "metadata": {},
   "source": [
    "#### Silhouette Plot\n",
    "Measures cluster balance, distribution of silhouette values per cluster, overlap between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a313ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(18, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, k in zip(axes, k_range):\n",
    "  km = KMeans(n_clusters=k, random_state=42)\n",
    "  labels = km.fit_predict(X_scaled)\n",
    "  \n",
    "  silhouette_vals = silhouette_samples(X_scaled, labels)\n",
    "  avg_score = silhouette_score(X_scaled, labels)\n",
    "  \n",
    "  y_lower = 0\n",
    "  for i in range(k):\n",
    "    cluster_vals = silhouette_vals[labels == i]\n",
    "    cluster_vals.sort()\n",
    "    y_upper = y_lower + len(cluster_vals)\n",
    "    \n",
    "    ax.barh(\n",
    "      range(y_lower, y_upper),\n",
    "      cluster_vals,\n",
    "      height=1\n",
    "    )\n",
    "    y_lower = y_upper\n",
    "  \n",
    "  ax.axvline(avg_score, color=\"red\", linestyle=\"--\")\n",
    "  ax.set_xlabel(\"Silhouette coefficient\")\n",
    "  ax.set_ylabel(\"Cluster\")\n",
    "  ax.set_title(f\"k={k}, avg={avg_score:.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5a532",
   "metadata": {},
   "source": [
    "### k=***6*** is the best k-value\n",
    "As concluded from the Elbow Method, Silhouette Score and Silhouette Plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_K = 6\n",
    "\n",
    "kmeans = KMeans(n_clusters=BEST_K, random_state=42)\n",
    "df[\"Cluster_KMeans\"] = kmeans.fit_predict(X_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df3134",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo = AgglomerativeClustering(\n",
    "  n_clusters=BEST_K,\n",
    "  linkage=\"ward\"\n",
    ")\n",
    "\n",
    "agg_labels = agglo.fit_predict(X_scaled)\n",
    "df[\"Cluster_Hierarchical\"] = agg_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7338eb45",
   "metadata": {},
   "source": [
    "#### Dendrogram with scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Create linkage matrix\n",
    "linkage_matrix = linkage(X_scaled, method='ward')\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(\n",
    "  linkage_matrix,\n",
    "  truncate_mode='lastp',  # show only last p merged clusters\n",
    "  p=30,                   # show last 30 merges\n",
    "  leaf_font_size=10,\n",
    "  show_contracted=True\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram\\n(Ward Linkage)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster Size', fontsize=12)\n",
    "plt.ylabel('Distance', fontsize=12)\n",
    "plt.axhline(y=7.5, color='r', linestyle='--', label='Cut at k=6')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d90b7",
   "metadata": {},
   "source": [
    "#### Dendrogram Analysis\n",
    "\n",
    "Ward linkage **minimises within-cluster variance** and is generally well-suited for **customer segmentation**.\n",
    "\n",
    "Hierarchical merging of clusters\n",
    "- **Leaves (bottom)** represent one data point each. Labels at the bottom are either individual samples or cluster sizes, depending on how they were truncated(shortened).\n",
    "- **Vertical lines** shows two clusters being merged. The longer this line, the more dissimilar/further apart the clusters being merged are.\n",
    "- **Height / Ward distance** indicates distance between merged clusters - substantial vertical jumps between merges suggest natural separations between clusters. \n",
    "- **Red line** suggests cutting at k=6 clusters (matching K-Means optimal k)\n",
    "\n",
    "Conclusion: The dendrogram confirms that 6 clusters (k=6) is best for natural groupings as there is a significant jump in merge distance after this point. This aligns with all our previous tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aceb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract best KMeans metrics\n",
    "k = BEST_K\n",
    "sil_k6 = evaluation_metrics['silhouette'][k]\n",
    "db_k6  = evaluation_metrics['davies_bouldin'][k]\n",
    "ch_k6  = evaluation_metrics['calinski_harabasz'][k]\n",
    "\n",
    "metrics_comparison = pd.DataFrame({\n",
    "  'Algorithm': ['K-Means', 'Hierarchical'],\n",
    "  'Silhouette Score': [\n",
    "    sil_k6,\n",
    "    silhouette_score(X_scaled, df['Cluster_Hierarchical'])\n",
    "  ],\n",
    "  'Davies-Bouldin Index': [\n",
    "    db_k6,\n",
    "    davies_bouldin_score(X_scaled, df['Cluster_Hierarchical'])\n",
    "  ],\n",
    "  'Calinski-Harabasz Score': [\n",
    "    ch_k6,\n",
    "    calinski_harabasz_score(X_scaled, df['Cluster_Hierarchical'])\n",
    "  ]\n",
    "})\n",
    "\n",
    "# print performance statistics for comparison\n",
    "metrics_comparison = metrics_comparison.round(3)\n",
    "metrics_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186dc3e",
   "metadata": {},
   "source": [
    "KMeans wins in all 3 metrics: It has a higher Silhouette Score, lower DBI and higher CH score than Hierarchical Clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3dce0",
   "metadata": {},
   "source": [
    "### Visual Comparison: KMeans VS Hierachical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# K-Means\n",
    "sns.scatterplot(\n",
    "  data=df, \n",
    "  x='Income (k$)', \n",
    "  y='Spending Score (1-99)',\n",
    "  hue='Cluster_KMeans',\n",
    "  palette='tab10',\n",
    "  ax=axes[0],\n",
    "  alpha=0.6\n",
    ")\n",
    "axes[0].set_title(f'K-Means Clustering\\nSilhouette: {metrics_comparison.iloc[0][\"Silhouette Score\"]:.3f}')\n",
    "axes[0].legend(title='Cluster', fontsize=8)\n",
    "\n",
    "# Hierarchical\n",
    "sns.scatterplot(\n",
    "  data=df,\n",
    "  x='Income (k$)',\n",
    "  y='Spending Score (1-99)', \n",
    "  hue='Cluster_Hierarchical',\n",
    "  palette='tab10',\n",
    "  ax=axes[1],\n",
    "  alpha=0.6\n",
    ")\n",
    "axes[1].set_title(f'Hierarchical Clustering\\nSilhouette: {metrics_comparison.iloc[1][\"Silhouette Score\"]:.3f}')\n",
    "axes[1].legend(title='Cluster', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939924e8",
   "metadata": {},
   "source": [
    "#### **Conclusion: KMeans is a more suitable algorithm.** We will use KMeans for further visualisations with PCA and t-SNE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c1fdd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Visualise Clusters with PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) # instantiate PCA\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5189a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15)) # 2rows x 3cols\n",
    "axes = axes.flatten() # flatten for easy indexing\n",
    "\n",
    "for idx, k in enumerate(k_range):\n",
    "  kmeans = KMeans(n_clusters=k, random_state=42) # instantiate kmeans with respective n_clusters\n",
    "  labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "  # project centroids into PCA space\n",
    "  centroids_pca = pca.transform(kmeans.cluster_centers_)\n",
    "\n",
    "  # generate scatter plot in corresponding subplot\n",
    "  ax = axes[idx]\n",
    "\n",
    "  # plot cluster points\n",
    "  scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, alpha=0.4, cmap=\"tab10\")\n",
    "\n",
    "  # plot centroids\n",
    "  ax.scatter(\n",
    "    centroids_pca[:, 0],\n",
    "    centroids_pca[:, 1],\n",
    "    c=\"black\", s=100, marker=\"X\", label=\"Centroids\", alpha=0.8\n",
    "  )\n",
    "  ax.set_title(f\"k={k}, silhouette={evaluation_metrics[\"silhouette\"][k]:.3f}\")\n",
    "  ax.set_xlabel(\"PC1\")\n",
    "  ax.set_ylabel(\"PC2\")\n",
    "  ax.legend()\n",
    "  print(f\"Subplot for k={k} completed.\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# generate silhouette score summary table\n",
    "print(\"PCA achieved an explained variance ratio of \", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654705e5",
   "metadata": {},
   "source": [
    "### Visualise Clusters with t-SNE\n",
    "t-distributed Stochastic Neighbor Embedding (t-SNE) is a dimensionality reduction technique for visualising high-dimensional data in 2D or 3D.  \n",
    "It preserves local structure so points that are close in high dimensions remain close in the 2D or 3D plot, making clusters visually meaningful.  \n",
    "\n",
    "#### How It Works:\n",
    "* Computes pairwise similarities between points in high-dimensional space.\n",
    "* Converts them into probabilities (how likely points are neighbours).\n",
    "* Places points in low-dimensional space (e.g., 2D) such that these neighbour probabilities are preserved.\n",
    "* Uses t-distribution in 2D to handle crowding (more spread for distant points, tighter for close points).\n",
    "* Optimises via gradient descent to minimise the difference (KL divergence) between high- and low-dimensional distributions.  \n",
    "💡 Analogy: Imagine a 3D ball of points — t-SNE “flattens” it onto paper while keeping close friends together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da8b3e8",
   "metadata": {},
   "source": [
    "#### Use k=6\n",
    "Concluded as the most optimal k-value based on the silhouette score (highest at 0.431) and the elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of t-SNE configs to compare\n",
    "tsne_configs = [\n",
    "  {\"perplexity\": 30, \"learning_rate\": 200, \"title\": \"Perplexity 30, LR 200\"},\n",
    "  {\"perplexity\": 50, \"learning_rate\": 200, \"title\": \"Perplexity 50, LR 200\"},\n",
    "  {\"perplexity\": 40, \"learning_rate\": 100, \"title\": \"Perplexity 40, LR 100\"},\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, cfg in enumerate(tsne_configs, 1):\n",
    "  tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=cfg[\"perplexity\"],\n",
    "    learning_rate=cfg[\"learning_rate\"],\n",
    "    random_state=42\n",
    "  )\n",
    "  X_tsne = tsne.fit_transform(X_scaled)\n",
    "  \n",
    "  plt.subplot(1, len(tsne_configs), i)\n",
    "  plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=df[\"Cluster_KMeans\"], alpha=0.6, cmap=\"tab10\")\n",
    "  plt.title(cfg[\"title\"])\n",
    "  plt.xlabel(\"t-SNE 1\")\n",
    "  plt.ylabel(\"t-SNE 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a6c07",
   "metadata": {},
   "source": [
    "Check by:\n",
    "- Looking for plots where clusters are most clearly separated and compact.\n",
    "- Avoiding plots where clusters overlap heavily or look scattered randomly.\n",
    "- Check consistency: run t-SNE a few times (random_state fixed for reproducibility) — prefer the configuration where clusters consistently separate.\n",
    "\n",
    "Perplexity 50, LR 200 shows the most distinct and compact clustering with minimal overlapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d3581b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STAGE 5: Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed552eef",
   "metadata": {},
   "source": [
    "### Interpret Customer Segmentation\n",
    "* **Cluster DataFrame**: Analytic Segmentation\n",
    "* **Radar Chart**: Visual Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b69859",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_means = df.groupby(\"Cluster_KMeans\")[features].mean()\n",
    "cluster_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6aa258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features for radar chart (0-1 scale)\n",
    "cluster_norm = (cluster_means - cluster_means.min()) / (cluster_means.max() - cluster_means.min())\n",
    "\n",
    "categories = list(cluster_norm.columns)\n",
    "N = len(categories)\n",
    "angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()\n",
    "angles += angles[:1] # complete the loop\n",
    "\n",
    "# setup subplots\n",
    "num_clusters = cluster_norm.shape[0]\n",
    "cols = 3\n",
    "rows = (num_clusters + 1) // cols\n",
    "\n",
    "plt.figure(figsize=(cols*4, rows*4))\n",
    "\n",
    "for i, (cluster_id, row) in enumerate(cluster_norm.iterrows(), 1):\n",
    "  values = row.tolist()\n",
    "  values += values[:1] # complete the loop\n",
    "  \n",
    "  ax = plt.subplot(rows, cols, i, polar=True)\n",
    "  ax.plot(angles, values, label=f\"Cluster {cluster_id}\", color=f\"C{cluster_id}\")\n",
    "  ax.fill(angles, values, alpha=0.2, color=f\"C{cluster_id}\")\n",
    "  ax.set_xticks(angles[:-1])\n",
    "  ax.set_xticklabels(categories)\n",
    "  ax.set_ylim(0, 1)\n",
    "  ax.set_title(f\"Cluster {cluster_id}\", size=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cluster_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f4587",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Interpretation of Customer Segments**\n",
    "\n",
    "#### Data Context / Recap on Dataset:\n",
    "1. Mean Age ≈ **39 years old**\n",
    "\n",
    "2. Mean Income ≈ **$60.6k**\n",
    "\n",
    "3. Spending Score reflects **spending tendency**, not affordability\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "##### **Cluster 0: Old Balanced Shoppers**\n",
    "\n",
    "Statistics\n",
    "- Age: ~56.3 (oldest cluster)\n",
    "- Income: ~$54.3k (slightly below average)\n",
    "- Spending Score: ~49.1 (moderate)\n",
    "\n",
    "Characteristics:\n",
    "1. Stable and needs-driven purchasing behaviour\n",
    "2. Spending aligns reasonably with income\n",
    "3. Likely values utility, reliability, and consistency\n",
    "\n",
    "Business implication: Reliable but limited growth potential. More suited for **retention-focused strategies**.\n",
    "##### **Cluster 1: Young & Rich Splurgers**\n",
    "\n",
    "Statistics\n",
    "- Age: ~32.7 (younger than average)\n",
    "- Income: ~$86.5k (well above average)\n",
    "- Spending Score: ~82.1 (very high)\n",
    "\n",
    "Characteristics:\n",
    "1. Strong purchasing power combined with high willingness to spend\n",
    "2. High engagement with discretionary and premium products\n",
    "3. Likely lifestyle-oriented and experience-driven consumers\n",
    "\n",
    "Business implication: Highest revenue potential. Key target for **premium offerings, upselling, and loyalty programmes**.\n",
    "\n",
    "\n",
    "##### **Cluster 2: Young & Impulsive Splurgers**\n",
    "\n",
    "Statistics\n",
    "- Age: ~25.6 (youngest cluster)\n",
    "- Income: ~$26.5k (lowest income)\n",
    "- Spending Score: ~76.2 (high)\n",
    "\n",
    "Characteristics:\n",
    "1. Spending behaviour is disproportionate to income level\n",
    "2. Likely impulsive or trend-driven purchasing behaviour\n",
    "3. Financially vulnerable but highly engaged consumers\n",
    "\n",
    "Business implication: High short-term engagement potential, but requires **careful positioning** to avoid churn or financial strain.\n",
    "\n",
    "\n",
    "##### **Cluster 3: Cautious Shoppers**\n",
    "\n",
    "Statistics\n",
    "- Age: ~26.1 (young)\n",
    "- Income: ~$59.4k (near average)\n",
    "- Spending Score: ~44.5 (moderate–low)\n",
    "\n",
    "Characteristics:\n",
    "1. Financially capable but spending-conscious\n",
    "2. Likely to compare prices and delay purchase decisions\n",
    "3. Rational, value-for-money oriented consumers\n",
    "\n",
    "Business implication: Responsive to **discounts and clear value propositions**, with moderate growth potential.\n",
    "\n",
    "\n",
    "##### **Cluster 4: Rich but Frugal Middle-Aged Shoppers**\n",
    "\n",
    "Statistics\n",
    "- Age: ~44.0\n",
    "- Income: ~$90.1k (highest among all clusters)\n",
    "- Spending Score: ~17.9 (lowest)\n",
    "\n",
    "Characteristics:\n",
    "1. Strong financial capacity but minimal discretionary spending\n",
    "2. Likely prioritises savings or long-term financial security\n",
    "3. Highly selective and deliberate purchasing behaviour\n",
    "\n",
    "Business implication: Difficult to activate; requires **trust-based, long-term value messaging** rather than short-term promotions.\n",
    "\n",
    "\n",
    "##### **Cluster 5: Ghost Shoppers (Low-Engagement)**\n",
    "\n",
    "Statistics\n",
    "- Age: ~45.5\n",
    "- Income: ~$26.3k (low)\n",
    "- Spending Score: ~19.4 (very low)\n",
    "\n",
    "Characteristics:\n",
    "1. Low purchasing power combined with low engagement\n",
    "2. Minimal participation in discretionary consumption\n",
    "3. Likely prioritises essential spending only\n",
    "\n",
    "Business implication: Lowest return on investment; **not a strategic focus for growth**.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### **\"Q: Which Cluster Needs the Most Attention?\"**\n",
    "\n",
    "##### A: Cluster 4 \"Rich but Frugal Middle-Aged\"\n",
    "\n",
    "- Highest income but lowest spending - why? They definitely have the capacity to spend more, yet they don't, showcasing huge untapped potential for the business. This strongly suggests that existing business strategies are likely ineffective for this customer segment - I investigate more below.\n",
    "\n",
    "- After inspecting the age range of the clusters with the highest and lowest spending, here's what I found:\n",
    "  1. Clusters 1 & 2 have the highest Spending. The mean age of customers in these groups is ~29years.\n",
    "  2. In contrast, Cluster 4 has the 2nd lowest Spending. The mean age of customers in this group is 44years.\n",
    "  \n",
    "  - The age gap is nearly 15years! This validates my hypothesis that the strategies employed are either too generalised or only effective for a younger audience (25-35years old).\n",
    "\n",
    "- Solution: **Devise marketing campaigns or strategies targeted at the middle-aged**. It is crucial to draw on this pool of untapped revenue to maximise business growth.\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Secondary Opportunity: Cluster 1 \"Young & Rich Splurgers\"\n",
    "\n",
    "- High engagement and spending is not guaranteed over time - factors like customer dissatisfaction, evolving needs and business relevance can cause businesses to lose loyal customers. It is up to the business to utilise smart strategies to maintain customer loyalty. Methods include but are not limited to: showing customers appreciation via loyalty programs, exclusive benefits (e.g. early access to new products).\n",
    "\n",
    "- The customers in this segment are ~33years old. However, the **age group is not a big consideration for the strategy as the focus is on minimising churn** (rate at which customers stop doing business with a company).\n",
    "\n",
    "- Since the average income of this customer group is exceptionally high, we should leverage their high SES (socio-economic status) to benefit not just the business, but the customers too. The business can organise invite-only connection dinners to give customers opportunities to expand their network if they continue to contribute to our business. **This adds an unique dimension to the loyalty programme by delivering value beyond transactions, aligning long-term customer wellbeing with the business strategy.**\n",
    "\n",
    "- Solution: A **combination of loyalty programs and exclusive benefits** will be the smoothest and most effective way to retain this valuable group of customers.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **\"Q: How I performed customer segmentation using unsupervised machine learning algorithms in Python?\"**\n",
    "\n",
    "##### A:\n",
    "\n",
    "First, I conducted exploratory data analysis (EDA) to understand the distribution and relationships between key variables such as age, income, and spending score. This helped identify potential patterns and informed subsequent preprocessing steps.\n",
    "\n",
    "Next, I carried out data preprocessing and feature engineering, which included scaling numerical features using StandardScaler to ensure fair distance-based clustering and preparing the dataset for dimensionality reduction and clustering algorithms.\n",
    "\n",
    "I then applied multiple clustering algorithms, specifically K-Means and Agglomerative Clustering, to avoid relying on a single method and to validate the robustness of the segmentation results.\n",
    "\n",
    "To determine the optimal number of clusters (k), I evaluated a range of k-values using several quantitative metrics:\n",
    "\n",
    "Elbow Method to analyse within-cluster variance\n",
    "\n",
    "Silhouette Score and Silhouette Plot to assess cluster separation and cohesion\n",
    "\n",
    "Davies–Bouldin Index and Calinski–Harabasz Score to compare clustering quality across k-values\n",
    "\n",
    "Based on the consistency of these metrics, I selected the best-performing value of k (k=6).\n",
    "\n",
    "To test and visualise clustering behaviour, I used:\n",
    "\n",
    "Initially, 2D scatter plots to visually compare clustering outcomes. But I realised the visuals weren't very accurate as I trained my model using 3 dimensions.\n",
    "\n",
    "So I used PCA for 2D visualisation across different k-values\n",
    "\n",
    "And t-SNE with varying perplexities and learning rates to inspect non-linear separability\n",
    "\n",
    "Hierarchical clustering dendrograms were also used to examine cluster structure and validate k selection\n",
    "\n",
    "Finally, I interpreted the resulting clusters by analysing cluster-level statistics and behavioural patterns, translating them into meaningful customer segments with clear business implications.\n",
    "\n",
    "<br>\n",
    "\n",
    "_by JEROME LOKE | DAAA/FT/1B/01 | P2510707_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
